# -*- coding: utf-8 -*-
"""final lrp

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QTiloZ7869_WFyke7uitrPzgzMnVlGVz
"""
prev_address = '/gpfs/home/shenjin/lrp+ace/'
TRAIN_PATH = prev_address+'S1/easy/Trains1_easy'
TEST_PATH = prev_address+'S1/easy/Tests1_easy'
TES = True

import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.models as models
from torch.optim.lr_scheduler import _LRScheduler
import torch.utils.data as data
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from sklearn import decomposition
from sklearn import manifold
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from tqdm import tqdm, trange
import matplotlib.pyplot as plt
from matplotlib import gridspec
import pandas as pd
from PIL import Image
from torchvision.transforms import Compose, Resize, CenterCrop
from torchvision.transforms import ToTensor, Normalize
from torchvision.models import vgg11_bn
from zennit.attribution import Gradient,SmoothGrad
from zennit.core import Stabilizer
from zennit.composites import EpsilonPlusFlat
from zennit.composites import SpecialFirstLayerMapComposite, NameMapComposite
from zennit.image import imgify, imsave
from zennit.rules import Epsilon, ZPlus, ZBox, Norm, Pass, Flat
from zennit.types import Convolution, Activation, AvgPool, Linear as AnyLinear
from zennit.types import BatchNorm, MaxPool
from zennit.torchvision import VGGCanonizer, ResNetCanonizer
import numpy as np
import copy
import random
import os
import cv2
import shutil
import subprocess


min_seed = 1
max_seed = 10000
seed_list = [seed for seed in range(min_seed, max_seed+1)]
SEED = seed_list.pop(random.randint(min_seed,len(seed_list)))
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.backends.cudnn.deterministic = True

pretrained_size = (224,224)
pretrained_means = [0.485, 0.456, 0.406]
pretrained_stds = [0.229, 0.224, 0.225]
train_transforms = transforms.Compose([
                           transforms.Resize(pretrained_size),
                           transforms.RandomRotation(5),
                           transforms.RandomHorizontalFlip(0.5),
                           transforms.RandomCrop(pretrained_size, padding=10),
                           transforms.ToTensor(),
                           transforms.Normalize(mean=pretrained_means,
                                                std=pretrained_stds)
                       ])
test_transforms = transforms.Compose([
                           transforms.Resize(pretrained_size),
                           transforms.ToTensor(),
                           transforms.Normalize(mean=pretrained_means,
                                                std=pretrained_stds)
                       ])
train_data = datasets.ImageFolder(TRAIN_PATH,
                            transform=train_transforms)

test_data = datasets.ImageFolder(TEST_PATH,
                             
                             transform=test_transforms)
VALID_RATIO = 0.9
n_train_examples = int(len(train_data) * VALID_RATIO)
n_valid_examples = len(train_data) - n_train_examples
train_data, valid_data = data.random_split(train_data,
                                           [n_train_examples, n_valid_examples])
valid_data = copy.deepcopy(valid_data)
valid_data.dataset.transform = test_transforms

images_alltestoi, labels_gt = zip(*[(image, label) for image, label in
                       test_data])
classes = test_data.classes

ima = [pic[None] for pic in images_alltestoi]

BATCH_SIZE = 8
train_iterator = data.DataLoader(train_data,
                                 shuffle=True,
                                 batch_size=BATCH_SIZE)
valid_iterator = data.DataLoader(valid_data,
                                 batch_size=BATCH_SIZE)
test_iterator = data.DataLoader(test_data,
                                batch_size=BATCH_SIZE)

class VGG(nn.Module):
    def __init__(self, features, output_dim):
        super().__init__()

        self.features = features

        self.avgpool = nn.AdaptiveAvgPool2d(7)

        self.classifier = nn.Sequential(
            nn.Linear(512 * 7 * 7, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(4096, output_dim),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        h = x.view(x.shape[0], -1)
        x = self.classifier(h)
        return x, h

vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']

vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512,
                512, 'M']

vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512,
                'M', 512, 512, 512, 'M']

vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512,
                512, 512, 'M', 512, 512, 512, 512, 'M']

def get_vgg_layers(config, batch_norm):

    layers = []
    in_channels = 3

    for c in config:
        assert c == 'M' or isinstance(c, int)
        if c == 'M':
            layers += [nn.MaxPool2d(kernel_size=2)]
        else:
            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)
            if batch_norm:
                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]
            else:
                layers += [conv2d, nn.ReLU(inplace=True)]
            in_channels = c

    return nn.Sequential(*layers)

OUTPUT_DIM = len(set(labels_gt))
vgg11_layers = get_vgg_layers(vgg11_config, batch_norm=True)
model = VGG(vgg11_layers, OUTPUT_DIM)
pretrained_model = models.vgg11_bn()
IN_FEATURES = pretrained_model.classifier[-1].in_features
final_fc = nn.Linear(IN_FEATURES, 14)
pretrained_model.classifier[-1] = final_fc

pretrained_model.load_state_dict(torch.load(prev_address+"SAVE_DIR/tut4-model.pt"))
IN_FEATURES = pretrained_model.classifier[-1].in_features
final_fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)
pretrained_model.classifier[-1] = final_fc
model = pretrained_model

START_LR = 1e-7
optimizer = optim.Adam(model.parameters(), lr=START_LR)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
criterion = nn.CrossEntropyLoss()
model = model.to(device)
criterion = criterion.to(device)

FOUND_LR = 5e-4
params = [
          {'params': model.features.parameters(), 'lr': FOUND_LR / 10},
          {'params': model.classifier.parameters()}
         ]
optimizer = optim.Adam(params, lr=FOUND_LR)

def calculate_accuracy(y_pred, y):
    top_pred = y_pred.argmax(1, keepdim=True)
    correct = top_pred.eq(y.view_as(top_pred)).sum()
    acc = correct.float() / y.shape[0]
    return acc

def train(model, iterator, optimizer, criterion, device):

    epoch_loss = 0
    epoch_acc = 0

    model.train()

    for (x, y) in tqdm(iterator, desc="Training", leave=False):

        x = x.to(device)
        y = y.to(device)

        optimizer.zero_grad()

        y_pred = model(x)

        loss = criterion(y_pred, y)

        acc = calculate_accuracy(y_pred, y)

        loss.backward()

        optimizer.step()

        epoch_loss += loss.item()
        epoch_acc += acc.item()

    return epoch_loss / len(iterator), epoch_acc / len(iterator)

def evaluate(model, iterator, criterion, device):

    epoch_loss = 0
    epoch_acc = 0

    model.eval()

    with torch.no_grad():

        for (x, y) in tqdm(iterator, desc="Evaluating", leave=False):

            x = x.to(device)
            y = y.to(device)

            y_pred = model(x)

            loss = criterion(y_pred, y)

            acc = calculate_accuracy(y_pred, y)

            epoch_loss += loss.item()
            epoch_acc += acc.item()

    return epoch_loss / len(iterator), epoch_acc / len(iterator)

def epoch_time(start_time, end_time):
    elapsed_time = end_time - start_time
    elapsed_mins = int(elapsed_time / 60)
    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))
    return elapsed_mins, elapsed_secs
  
EPOCHS = 10
best_valid_loss = float('inf')
for epoch in trange(EPOCHS, desc="Epochs"):

    start_time = time.monotonic()

    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)
    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)

    if valid_loss < best_valid_loss:
        best_valid_loss = valid_loss
        torch.save(model.state_dict(), 'tut4-model.pt')

    end_time = time.monotonic()

    epoch_mins, epoch_secs = epoch_time(start_time, end_time)
    
    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')
    print(f'\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')
    print(f'\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')
  
model.load_state_dict(torch.load('tut4-model.pt'))

def get_predictions(model, iterator):

    model.eval()

    images = []
    labels = []
    probs = []

    with torch.no_grad():

        for (x, y) in tqdm(iterator):

            x = x.to(device)

            y_pred = model(x)

            y_prob = F.softmax(y_pred, dim=-1)

            images.append(x.cpu())
            labels.append(y.cpu())
            probs.append(y_prob.cpu())

    images = torch.cat(images, dim=0)
    labels = torch.cat(labels, dim=0)
    probs = torch.cat(probs, dim=0)

    return images, labels, probs

images, labels, probs = get_predictions(model, test_iterator)
pred_labels = torch.argmax(probs, 1)

all_pred_label = [int(asdf) for asdf in pred_labels]
all_probnumb = [a for a in probs.tolist()]
all_probnum = np.round(all_probnumb,3)

stacked = torch.stack((labels, pred_labels), dim=1)
labe=[]
pred=[]
for row in stacked:
    labels_, pred_labels_ = row.numpy()
    labe.append(labels_)
    pred.append(pred_labels_)

cmatrix=confusion_matrix(labe, pred)

FP = cmatrix.sum(axis=0) - np.diag(cmatrix)  

FN = cmatrix.sum(axis=1) - np.diag(cmatrix)

TP = np.diag(cmatrix)

TN = cmatrix.sum() - (FP + FN + TP)


#Overall Acc
ovAcc = np.sum(TP) / (np.sum(FN) + np.sum(TP))
print('OvAcc = ',ovAcc, '\n')
# Sensitivity, hit rate, recall, or true positive rate
TPR = np.round(TP/(TP+FN),2)
print('TPR:',TPR, '\n')
# Specificity or true negative rate
TNR = np.round(TN/(TN+FP),2)
print('TNR:',TNR, '\n')
# Precision or positive predictive value
PPV = np.round(TP/(TP+FP),2)
print('PPV:',PPV, '\n')
# Negative predictive value
NPV = np.round(TN/(TN+FN),2)
print('NPV:',NPV, '\n')
# Fall out or false positive rate
FPR = np.round(FP/(FP+TN),2)
print('FPR:',FPR, '\n')
# False negative rate
FNR = np.round(FN/(TP+FN),2)
print('FNR:',FNR, '\n')
# False discovery rate
FDR = np.round(FP/(TP+FP),2)
print('FDR:',FDR, '\n')
# Overall accuracy
ACC = np.round((TP+TN)/(TP+FP+FN+TN),2)
print('ACC:',ACC, '\n')

tablevalue = np.vstack(([a[:6] for a in classes],TPR,TNR,PPV,NPV,FPR,FNR,FDR,ACC))

fig, ax = plt.subplots(figsize =(4,3),tight_layout=True )

ax.axis('off')

df = pd.DataFrame(tablevalue, index=['class','TPR','TNR','PPV','NPV','FPR','FNR','FDR','ACC'])

a=ax.table(cellText=df.values, rowLabels=df.index, loc='upper center')
a.set_fontsize(10)
a.scale(0.8,2)

fig.patch.set_facecolor('xkcd:charcoal grey')
plt.title(label=f'ovacc={ovAcc}',
          fontsize=10,
          color="xkcd:robin's egg blue")

fig.savefig(prev_address+"right side/1.png",facecolor=fig.get_facecolor(),edgecolor='none',dpi=300)

def get_representations(model, iterator):

    model.eval()

    outputs = []
    labels = []

    with torch.no_grad():

        for (x, y) in tqdm(iterator):

            x = x.to(device)

            y_pred = model(x)

            outputs.append(y_pred.cpu())
            labels.append(y)

    outputs = torch.cat(outputs, dim=0)
    labels = torch.cat(labels, dim=0)

    return outputs, labels

outputs, labels = get_representations(model, train_iterator)

device = torch.device("cpu")
for imag in ima:
  imag = imag.to(device)
model = model.to(device)
model=model.eval()# use the VGG-specific canonizer (alias for SequentialMergeBatchNorm, only
# needed with batch-norm)


if TES == False:
  canonizer = VGGCanonizer()
# the EpsilonGammaBox composite needs the lowest and highest values, which are
# here for ImageNet 0. and 1. with a different normalization for each channel
# create a composite, specifying arguments and the canonizers
  composite = EpsilonPlusFlat(canonizers=[canonizer])

else:
  composite = EpsilonPlusFlat()




w = 1
# choose a target class for the attribution (label 437 is lighthouse)
for data in ima:
  for i in range(OUTPUT_DIM):
    target = torch.eye(OUTPUT_DIM)[[i]]
# create the attributor, specifying model and composite
    if TES == False:
      with composite.context(model) as modified:
        data.requires_grad = True
        output, features = modified(data)
        attribution, = torch.autograd.grad(output, data, target)

    else:
      with Gradient(model=model, composite=composite) as attributor:
    # compute the model output and attribution
        output, attribution = attributor(data, target)
    relevance = attribution.sum(1)
# create an image of the visualize attribution
    img = imgify(relevance, symmetric=True, cmap='coldnhot')
    img.save(prev_address+"lrp map/%d.png" %(w))
    w+=1
#print(f'Prediction: {output.argmax(1)[0].item()}')

index = 1
all_path = []
for big_path in sorted(os.listdir(TEST_PATH)):
    full_path = os.path.join(TEST_PATH,big_path)
    for small_path in sorted(os.listdir(full_path)):
        final_path = os.path.join(full_path,small_path)
        all_path.append(final_path)
fig, axes = plt.subplots(OUTPUT_DIM+2, len(ima)+1, figsize=(68,30),tight_layout=True)
axes[0,0].axis('off')
axes[1,0].axis('off')

for ind in range(len(classes)):
  axes[ind+2,0].axis('off')
  axes[ind+2,0].text(0.5, 0.5, f'Class {ind}: \n {classes[ind][:6]}',
                   fontsize=30,color='#d2f2f7',horizontalalignment='center',verticalalignment='center')

for oi_num in range(len(ima)):
  axes[0,1+oi_num].axis('off')
  axes[0,1+oi_num].text(0.5, 0.5, f'True: \n {classes[labels_gt[oi_num]][:6]} \n Pred: \n {classes[all_pred_label[oi_num]][:6]}',
                        fontsize=30,color='#d2f2f7',horizontalalignment='center',verticalalignment='center')
  axes[1,1+oi_num].axis('off')

  
  img1 = cv2.imread(all_path[oi_num])
  img1 = cv2.resize(img1,(224,224))
  axes[1,1+oi_num].imshow(img1[:, :, ::-1])

  for col_leng in range(len(classes)):
    axes[col_leng+2,oi_num+1].axis('off')
    image_name = os.path.join(prev_address+r'lrp map', str(index)+'.png')
    img = plt.imread(image_name,0)
    axes[col_leng+2,oi_num+1].imshow(img)
    axes[col_leng+2,oi_num+1].set_title(f'{all_probnum[oi_num][col_leng]}', fontsize = '30',color="xkcd:robin's egg blue")
    index += 1
fig.patch.set_facecolor('xkcd:charcoal grey')
fig.savefig(prev_address+"lrp1/1.png",facecolor=fig.get_facecolor(),edgecolor='none')

fig = plt.figure()
 
# to change size of subplot's
# set height of each subplot as 8
fig.set_figheight(15)
 
# set width of each subplot as 8
fig.set_figwidth(30)
spec = gridspec.GridSpec(ncols=2, nrows=1,
                          wspace=0.05,
                         hspace=0.05,width_ratios=[1,0.5])
ax0 = fig.add_subplot(spec[0])
plt.imshow(Image.open(prev_address+'lrp1/1.png'))
plt.axis('off')

ax1 = fig.add_subplot(spec[1])
plt.imshow(Image.open(prev_address+'right side/1.png'))
plt.axis('off')
fig.patch.set_facecolor('xkcd:charcoal grey')
t = time.time()

dir = (prev_address+'ace_folder/final_imgs/%s' %str(t))
if not os.path.exists(dir):
    dir = dir
else:
    dir = dir+'1'
os.mkdir(dir)

fig.savefig(dir+'/_lrp.png',facecolor=fig.get_facecolor(),bbox_inches='tight',edgecolor='none',dpi=300)
cnames = ['HH_Fas','MM_Clo','Mukono','Scene','Trigger']
bsize = [8,8,8,8,8]
for fi,bsi in zip(cnames,bsize):
  while True:
  
    command = ["python",prev_address+"ace_folder/ace_run.py", "--target_class", fi, "--source_dir", prev_address+"ace_folder/%s" %(fi), "--working_dir", prev_address+"SAVE_DIR","--model_to_run", "mymodel", "--labels_path",prev_address+"VGG_class_index.json", "--feature_names", "features", "--num_random_exp", "11", "--max_imgs", "20", "--min_imgs", "1", "--bs", str(bsi)]
    try:
      result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
      output = result.stdout.decode().strip()
      print("success_batchsize=",bsi)
      break
    except subprocess.CalledProcessError as e:
      print(f"Error: {e.stderr.decode().strip()}")
      print("error_batchsize=",bsi)
      bsi = bsi+1
      if bsi == 12:
        print("final_bs = 12")
        break
  if os.path.isfile(prev_address+'SAVE_DIR/results/features.png'):
    os.rename(prev_address+'SAVE_DIR/results/features.png',prev_address+'SAVE_DIR/results/%s.png'%(fi))
    shutil.move(prev_address+'SAVE_DIR/results/%s.png'%fi, dir)